{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eb8oQyN5sHg",
        "outputId": "f9c6797b-78d2-424f-8e86-48f00275776d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel, Trainer, TrainingArguments\n",
        "from datasets import DatasetDict, concatenate_datasets, load_dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "ds = load_dataset(\"PiC/phrase_similarity\")\n",
        "\n",
        "train_label0 = ds['train'].filter(lambda x: x['label'] == 0)\n",
        "train_label1 = ds['train'].filter(lambda x: x['label'] == 1)\n",
        "\n",
        "train_label0 = train_label0.shuffle(seed=42)\n",
        "train_label1 = train_label1.shuffle(seed=42)\n",
        "\n",
        "train_label0 = train_label0.select(range(500))\n",
        "train_label1 = train_label1.select(range(500))\n",
        "\n",
        "balanced_train = concatenate_datasets([train_label0, train_label1])\n",
        "\n",
        "ds = DatasetDict({\n",
        "    'train': balanced_train,\n",
        "    'validation': ds['validation'],\n",
        "    'test': ds['test']\n",
        "})\n",
        "\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    tokenized_s1 = tokenizer(\n",
        "        examples['phrase1'],\n",
        "        examples['sentence1'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128\n",
        "    )\n",
        "    tokenized_s2 = tokenizer(\n",
        "        examples['phrase2'],\n",
        "        examples['sentence2'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128\n",
        "    )\n",
        "    examples['input_ids_s1'] = tokenized_s1['input_ids']\n",
        "    examples['attention_mask_s1'] = tokenized_s1['attention_mask']\n",
        "    examples['input_ids_s2'] = tokenized_s2['input_ids']\n",
        "    examples['attention_mask_s2'] = tokenized_s2['attention_mask']\n",
        "    return examples\n",
        "\n",
        "tokenized_ds = ds.map(tokenize_function, batched=True)\n",
        "\n",
        "tokenized_ds = tokenized_ds.remove_columns(['phrase1', 'phrase2', 'sentence1', 'sentence2', 'idx'])\n",
        "\n",
        "# Rename 'label' to 'labels'\n",
        "tokenized_ds = tokenized_ds.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# Set format to PyTorch tensors\n",
        "tokenized_ds.set_format(type='torch', columns=['input_ids_s1', 'attention_mask_s1',\n",
        "                                               'input_ids_s2', 'attention_mask_s2', 'labels'])\n",
        "\n",
        "# Define the model classes\n",
        "class BaseBERTModel(nn.Module):\n",
        "    def __init__(self, model_name='bert-base-uncased'):\n",
        "        super(BaseBERTModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "        for param in self.bert.embeddings.parameters():\n",
        "            param.requires_grad = True # this is the main part here when I say with_grad\n",
        "\n",
        "    def forward(self, input_ids_s1, attention_mask_s1, input_ids_s2, attention_mask_s2):\n",
        "        outputs_s1 = self.bert(input_ids=input_ids_s1, attention_mask=attention_mask_s1)\n",
        "        outputs_s2 = self.bert(input_ids=input_ids_s2, attention_mask=attention_mask_s2)\n",
        "        return outputs_s1.last_hidden_state, outputs_s2.last_hidden_state\n",
        "\n",
        "class PoolingModel(nn.Module):\n",
        "    def __init__(self, model_name='bert-base-uncased', hidden_size=768, num_classes=2):\n",
        "        super(PoolingModel, self).__init__()\n",
        "        self.base_model = BaseBERTModel(model_name)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.classifier = nn.Linear(hidden_size * 2, num_classes)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, input_ids_s1, attention_mask_s1, input_ids_s2, attention_mask_s2, labels=None):\n",
        "        last_hidden_s1, last_hidden_s2 = self.base_model(input_ids_s1, attention_mask_s1, input_ids_s2, attention_mask_s2)\n",
        "        pooled_s1 = self.pool(last_hidden_s1.permute(0, 2, 1)).squeeze(-1)\n",
        "        pooled_s2 = self.pool(last_hidden_s2.permute(0, 2, 1)).squeeze(-1)\n",
        "        combined = torch.cat((pooled_s1, pooled_s2), dim=1)\n",
        "        logits = self.classifier(combined)\n",
        "        outputs = {'logits': logits}\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "            outputs['loss'] = loss\n",
        "        return outputs\n",
        "\n",
        "# Define metrics\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    return {'accuracy': acc, 'f1': f1}\n",
        "\n",
        "# Training and evaluation function\n",
        "def train_evaluate_model(model_class, strategy_name):\n",
        "    print(f\"\\n=== Training Model with {strategy_name} Strategy ===\")\n",
        "    model = model_class().to(device)  # Move model to GPU\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f'./results_{strategy_name}',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=64,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_dir=f'./logs_{strategy_name}',\n",
        "        logging_steps=100,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        greater_is_better=True\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_ds['train'],\n",
        "        eval_dataset=tokenized_ds['validation'],\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate(tokenized_ds['validation'])\n",
        "    print(f\"Validation Results for {strategy_name} Strategy: {eval_results}\")\n",
        "    return trainer, eval_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "McszbsvD6-k0",
        "outputId": "43b52cca-e870-49c2-cc93-ee7968dd9f88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Training Model with PoolingModel Strategy ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [189/189 03:45, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.717133</td>\n",
              "      <td>0.489000</td>\n",
              "      <td>0.398987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.654100</td>\n",
              "      <td>0.730591</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.485832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.654100</td>\n",
              "      <td>0.736013</td>\n",
              "      <td>0.534000</td>\n",
              "      <td>0.529665</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results for PoolingModel Strategy: {'eval_loss': 0.7360132932662964, 'eval_accuracy': 0.534, 'eval_f1': 0.5296653962922292, 'eval_runtime': 14.7351, 'eval_samples_per_second': 67.865, 'eval_steps_per_second': 1.086, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate the PoolingModel\n",
        "trainer, eval_results = train_evaluate_model(PoolingModel, \"PoolingModel\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "5HBZ-ZEM7bbB",
        "outputId": "9847b74d-1e89-48b7-80e2-7017b1f01b0c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='48' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:44]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Results: {'eval_loss': 0.7363443970680237, 'eval_accuracy': 0.52, 'eval_f1': 0.5155351721465022, 'eval_runtime': 30.2219, 'eval_samples_per_second': 66.177, 'eval_steps_per_second': 1.059, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_results = trainer.evaluate(tokenized_ds['test'])\n",
        "\n",
        "# Print the test results\n",
        "print(\"Test Results:\", test_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-hyxHBDV8Ptx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class AveragingModel(nn.Module):\n",
        "    def __init__(self, model_name='bert-base-uncased', hidden_size=768, num_classes=2):\n",
        "        super(AveragingModel, self).__init__()\n",
        "        self.base_model = BaseBERTModel(model_name)\n",
        "        self.classifier = nn.Linear(hidden_size * 2, num_classes)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, input_ids_s1, attention_mask_s1, input_ids_s2, attention_mask_s2, labels=None):\n",
        "        # Move inputs to GPU if available\n",
        "        input_ids_s1 = input_ids_s1.to(device)\n",
        "        attention_mask_s1 = attention_mask_s1.to(device)\n",
        "        input_ids_s2 = input_ids_s2.to(device)\n",
        "        attention_mask_s2 = attention_mask_s2.to(device)\n",
        "        if labels is not None:\n",
        "            labels = labels.to(device)\n",
        "\n",
        "        # Get last hidden states for both sequences\n",
        "        last_hidden_s1, last_hidden_s2 = self.base_model(input_ids_s1, attention_mask_s1,\n",
        "                                                         input_ids_s2, attention_mask_s2)\n",
        "\n",
        "        # Compute mean pooling for s1\n",
        "        mask_s1 = attention_mask_s1.unsqueeze(-1).expand(last_hidden_s1.size()).float()\n",
        "        mean_s1 = torch.sum(last_hidden_s1 * mask_s1, dim=1) / torch.clamp(mask_s1.sum(dim=1), min=1e-9)\n",
        "\n",
        "        # Compute mean pooling for s2\n",
        "        mask_s2 = attention_mask_s2.unsqueeze(-1).expand(last_hidden_s2.size()).float()\n",
        "        mean_s2 = torch.sum(last_hidden_s2 * mask_s2, dim=1) / torch.clamp(mask_s2.sum(dim=1), min=1e-9)\n",
        "\n",
        "        # Concatenate mean embeddings\n",
        "        combined = torch.cat((mean_s1, mean_s2), dim=1)  # (batch_size, hidden_dim * 2)\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(combined)  # (batch_size, num_classes)\n",
        "\n",
        "        # Prepare outputs\n",
        "        outputs = {'logits': logits}\n",
        "\n",
        "        # Add loss if labels are provided\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "            outputs['loss'] = loss\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "h7J74r8v9J5W",
        "outputId": "40d3d27b-1291-4c61-9eec-e38fd1b69c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Training Model with AveragingModel Strategy ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [189/189 03:41, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.689924</td>\n",
              "      <td>0.536000</td>\n",
              "      <td>0.453768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.610300</td>\n",
              "      <td>0.757975</td>\n",
              "      <td>0.608000</td>\n",
              "      <td>0.588062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.610300</td>\n",
              "      <td>1.147776</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.607191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results for AveragingModel Strategy: {'eval_loss': 1.1477761268615723, 'eval_accuracy': 0.615, 'eval_f1': 0.6071905554325545, 'eval_runtime': 14.6851, 'eval_samples_per_second': 68.096, 'eval_steps_per_second': 1.09, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate the PoolingModel\n",
        "trainer_avg, eval_results_avg = train_evaluate_model(AveragingModel, \"AveragingModel\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "edruScLK9WQl",
        "outputId": "242ecc95-a536-420e-a62f-44626004445c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='48' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:45]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Results: {'eval_loss': 1.136587142944336, 'eval_accuracy': 0.624, 'eval_f1': 0.6121212121212122, 'eval_runtime': 30.0289, 'eval_samples_per_second': 66.603, 'eval_steps_per_second': 1.066, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_results_avg = trainer_avg.evaluate(tokenized_ds['test'])\n",
        "\n",
        "# Print the test results\n",
        "print(\"Test Results:\", test_results_avg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPtI1U4RAgQX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
